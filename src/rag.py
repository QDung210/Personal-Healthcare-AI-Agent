from dataclasses import dataclass
from qdrant_client import QdrantClient
from model import EMBEDDER, QDRANT_CLIENT, RAG_AGENT
from sentence_transformers import SentenceTransformer
from typing import List, Optional, Dict
from pydantic import BaseModel
import textwrap


@dataclass
class Deps:
    qdrant: QdrantClient
    embedder: SentenceTransformer

DEPS = Deps(qdrant=QDRANT_CLIENT, embedder=EMBEDDER)

class SourceModel(BaseModel):
    title: str
    url: Optional[str] = None
    score: Optional[float] = None
    metadata: Dict[str, Optional[str]] = {}
    snippet: Optional[str] = None

class RAGResult(BaseModel):
    answer: str
    sources: List[SourceModel]


def retrieve_documents(deps: Deps, query: str, limit: int = 5):
    """TÃ¬m kiáº¿m tÃ i liá»‡u y táº¿ tá»« Qdrant"""
    print(f"ğŸ“Š Search query gá»­i Ä‘áº¿n Qdrant: '{query}'")
    qvec = deps.embedder.encode(query).tolist()
    hits = deps.qdrant.query_points(
        collection_name="medical_collection",
        query=qvec,
        limit=limit,
        with_payload=True,
    ).points

    docs = []
    for hit in hits:
        payload = getattr(hit, "payload", {}) or {}
        metadata = payload.get("metadata", {}) if isinstance(payload, dict) else {}
        content = payload.get("page_content", "") or metadata.get("text", "") or metadata.get("content", "")
        if not content:
            continue
        score = getattr(hit, "score", None)
        title = metadata.get("title", "KhÃ´ng cÃ³ tiÃªu Ä‘á»")
        print(f"   âœ“ TÃ¬m tháº¥y: '{title[:60]}...' (score: {round(score, 3) if score else 'N/A'})")
        docs.append({
            "title": title,
            "content": content[:1500],
            "score": round(score, 3) if score else None,
            "metadata": metadata
        })
    context = "\n\n".join(f"[Nguá»“n {i+1}] {d['content']}" for i, d in enumerate(docs))
    return context, docs

async def search_medical_info(query: str, chat_history: str = "") -> RAGResult:
    print(f"ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin vá»: {query}")
    
    # Náº¿u cÃ³ lá»‹ch sá»­ chat, táº¡o query má»Ÿ rá»™ng Ä‘á»ƒ tÃ¬m kiáº¿m tá»‘t hÆ¡n
    search_query = query
    if chat_history:
        # TrÃ­ch xuáº¥t chá»§ Ä‘á» chÃ­nh tá»« lá»‹ch sá»­ (cÃ¢u há»i gáº§n nháº¥t cá»§a user)
        lines = chat_history.strip().split('\n')
        for line in reversed(lines):
            if line.startswith("NgÆ°á»i dÃ¹ng:") and not line.endswith(query):
                previous_question = line.replace("NgÆ°á»i dÃ¹ng:", "").strip()
                # Náº¿u cÃ¢u há»i hiá»‡n táº¡i ngáº¯n vÃ  cÃ³ tá»« nhÆ° "cÃ²n", "thÃªm", "ná»¯a" thÃ¬ káº¿t há»£p vá»›i cÃ¢u trÆ°á»›c
                if len(query.split()) <= 10 and any(kw in query.lower() for kw in ["cÃ²n", "thÃªm", "ná»¯a", "khÃ¡c", "nÃ o", "nÃ o khÃ¡c", "gÃ¬ ná»¯a"]):
                    search_query = f"{previous_question} {query}"
                    print(f"ğŸ” Má»Ÿ rá»™ng tÃ¬m kiáº¿m: {search_query}")
                break
    
    context, docs = retrieve_documents(DEPS, search_query, limit=5)  # TÄƒng lÃªn 5 Ä‘á»ƒ cÃ³ nhiá»u lá»±a chá»n
    
    # Lá»c docs theo Ä‘á»™ liÃªn quan (chá»‰ giá»¯ láº¡i score >= 0.6)
    filtered_docs = [d for d in docs if d.get('score', 0) >= 0.6]
    
    if not filtered_docs:
        # Náº¿u khÃ´ng cÃ³ doc nÃ o Ä‘á»§ Ä‘iá»ƒm, thá»­ giáº£m xuá»‘ng 0.5
        filtered_docs = [d for d in docs if d.get('score', 0) >= 0.5]
        if not filtered_docs:
            return RAGResult(
                answer=" KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘á»§ chÃ­nh xÃ¡c trong cÆ¡ sá»Ÿ dá»¯ liá»‡u. Vui lÃ²ng há»i cÃ¡ch khÃ¡c hoáº·c Ä‘áº·t lá»‹ch khÃ¡m Ä‘á»ƒ Ä‘Æ°á»£c bÃ¡c sÄ© tÆ° váº¥n trá»±c tiáº¿p.",
                sources=[]
            )
    
    # Rebuild context tá»« filtered docs
    context = "\n\n".join(f"[Nguá»“n {i+1}] {d['content']}" for i, d in enumerate(filtered_docs))
    docs = filtered_docs  # Sá»­ dá»¥ng docs Ä‘Ã£ lá»c
    
    if not docs:
        return RAGResult(
            answer=" KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u. Vui lÃ²ng há»i cÃ¡ch khÃ¡c hoáº·c Ä‘áº·t lá»‹ch khÃ¡m Ä‘á»ƒ Ä‘Æ°á»£c bÃ¡c sÄ© tÆ° váº¥n trá»±c tiáº¿p.",
            sources=[]
        )

    # Táº¡o prompt cho RAG vá»›i lá»‹ch sá»­ chat
    context_section = f"\nLá»ŠCH Sá»¬ Há»˜I THOáº I:\n{chat_history}\n" if chat_history else ""
    
    prompt = textwrap.dedent(f"""
        Báº¡n lÃ  bÃ¡c sÄ© y táº¿ chuyÃªn nghiá»‡p. Dá»±a trÃªn thÃ´ng tin sau, hÃ£y tráº£ lá»i cÃ¢u há»i "{query}" báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch chi tiáº¿t, dá»… hiá»ƒu.
        {context_section}
        QUAN TRá»ŒNG: Náº¿u cÃ¢u há»i hiá»‡n táº¡i Ä‘á» cáº­p Ä‘áº¿n "cÃ²n", "thÃªm", "ná»¯a", "khÃ¡c" thÃ¬ hÃ£y dá»±a vÃ o lá»‹ch sá»­ há»™i thoáº¡i Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng Ä‘ang há»i tiáº¿p vá» chá»§ Ä‘á» nÃ o.
        
        HÃ£y trÃ­ch dáº«n nguá»“n báº±ng cÃ¡ch viáº¿t [Nguá»“n 1], [Nguá»“n 2] khi sá»­ dá»¥ng thÃ´ng tin tá»« tÃ i liá»‡u.
        
        Dá»® LIá»†U Y Táº¾:
        {context}
        
        Tráº£ lá»i:
    """)

    # Gá»i RAG Agent Ä‘á»ƒ sinh vÄƒn báº£n
    result = await RAG_AGENT.run(prompt, deps=DEPS)
    answer = str(result.output)

    # Format sources
    sources_out = []
    for i, d in enumerate(docs, start=1):
        m = d.get("metadata", {}) or {}
        url = m.get("url") or m.get("source_url") or m.get("link") or "N/A"
        snippet = (d.get("content")[:300] + "...") if d.get("content") else ""
        sources_out.append(SourceModel(
            title=d.get("title", f"Nguá»“n {i}"),
            url=url,
            score=d.get("score"),
            metadata={k: str(v) for k, v in m.items()},
            snippet=snippet
        ))
    
    return RAGResult(answer=answer, sources=sources_out)

